{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:01:20.075448Z",
     "start_time": "2024-11-20T19:01:20.061447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuration\n",
    "BASE_DIRECTORY = r\"C:\\Users\\howar\\football_research_advanced\\2.0\\England\\Football_Predictions\\data\"\n",
    "DATABASE_PATH = os.path.join(BASE_DIRECTORY, \"football_data.db\")\n",
    "BASE_URL = \"https://v3.football.api-sports.io\"\n",
    "API_KEY = os.getenv(\"x-rapidapi-key\")"
   ],
   "id": "2dc30090e296b8c3",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "93187341f95800a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:01:28.311149Z",
     "start_time": "2024-11-20T19:01:20.093449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuration\n",
    "BASE_DIRECTORY = r\"C:\\Users\\howar\\football_research_advanced\\2.0\\England\\Football_Predictions\\data\"\n",
    "DATABASE_PATH = os.path.join(BASE_DIRECTORY, \"football_data.db\")\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Step 1: Fetch Training Data\n",
    "def get_training_data():\n",
    "    conn = sqlite3.connect(DATABASE_PATH)\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "        f.fixture_id,\n",
    "        f.date,\n",
    "        f.home_team AS home_team_name,\n",
    "        f.away_team AS away_team_name,\n",
    "        f.home_goals,\n",
    "        f.away_goals,\n",
    "        s1.league_position AS home_league_position,\n",
    "        s2.league_position AS away_league_position,\n",
    "        s1.points AS home_points,\n",
    "        s2.points AS away_points,\n",
    "        rf_home.rolling_points AS home_rolling_points,\n",
    "        rf_home.rolling_wins AS home_rolling_wins,\n",
    "        rf_home.rolling_draws AS home_rolling_draws,\n",
    "        rf_home.rolling_losses AS home_rolling_losses,\n",
    "        rf_away.rolling_points AS away_rolling_points,\n",
    "        rf_away.rolling_wins AS away_rolling_wins,\n",
    "        rf_away.rolling_draws AS away_rolling_draws,\n",
    "        rf_away.rolling_losses AS away_rolling_losses,\n",
    "        fs1.shots_on_goal AS home_shots_on_goal,\n",
    "        fs2.shots_on_goal AS away_shots_on_goal,\n",
    "        fs1.shots_off_goal AS home_shots_off_goal,\n",
    "        fs2.shots_off_goal AS away_shots_off_goal,\n",
    "        fs1.total_shots AS home_total_shots,\n",
    "        fs2.total_shots AS away_total_shots,\n",
    "        fs1.blocked_shots AS home_blocked_shots,\n",
    "        fs2.blocked_shots AS away_blocked_shots,\n",
    "        fs1.shots_insidebox AS home_shots_insidebox,\n",
    "        fs2.shots_insidebox AS away_shots_insidebox,\n",
    "        fs1.shots_outsidebox AS home_shots_outsidebox,\n",
    "        fs2.shots_outsidebox AS away_shots_outsidebox,\n",
    "        fs1.ball_possession AS home_ball_possession,\n",
    "        fs2.ball_possession AS away_ball_possession,\n",
    "        fs1.yellow_cards AS home_yellow_cards,\n",
    "        fs2.yellow_cards AS away_yellow_cards,\n",
    "        fs1.red_cards AS home_red_cards,\n",
    "        fs2.red_cards AS away_red_cards,\n",
    "        fs1.goalkeeper_saves AS home_goalkeeper_saves,\n",
    "        fs2.goalkeeper_saves AS away_goalkeeper_saves,\n",
    "        fs1.total_passes AS home_total_passes,\n",
    "        fs2.total_passes AS away_total_passes,\n",
    "        fs1.passes_accurate AS home_passes_accurate,\n",
    "        fs2.passes_accurate AS away_passes_accurate,\n",
    "        fs1.passes_percentage AS home_passes_percentage,\n",
    "        fs2.passes_percentage AS away_passes_percentage\n",
    "    FROM fixtures f\n",
    "    LEFT JOIN standings s1\n",
    "        ON f.home_team_id = s1.team_id AND f.league_season = s1.season\n",
    "    LEFT JOIN standings s2\n",
    "        ON f.away_team_id = s2.team_id AND f.league_season = s2.season\n",
    "    LEFT JOIN recent_form rf_home ON f.home_team_id = rf_home.team_id\n",
    "    LEFT JOIN recent_form rf_away ON f.away_team_id = rf_away.team_id\n",
    "    LEFT JOIN fixture_statistics fs1\n",
    "        ON f.fixture_id = fs1.fixture_id AND f.home_team_id = fs1.team_id\n",
    "    LEFT JOIN fixture_statistics fs2\n",
    "        ON f.fixture_id = fs2.fixture_id AND f.away_team_id = fs2.team_id\n",
    "    WHERE f.status = 'Match Finished';\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "# Step 2: Prepare Features\n",
    "def prepare_features(df):\n",
    "    df['result'] = df.apply(\n",
    "        lambda row: 0 if row['home_goals'] > row['away_goals'] else\n",
    "        (2 if row['home_goals'] < row['away_goals'] else 1), axis=1\n",
    "    )\n",
    "\n",
    "    features = [\n",
    "        'home_league_position', 'away_league_position', 'home_points', 'away_points',\n",
    "        'home_rolling_points', 'home_rolling_wins', 'home_rolling_draws', 'home_rolling_losses',\n",
    "        'away_rolling_points', 'away_rolling_wins', 'away_rolling_draws', 'away_rolling_losses',\n",
    "        'home_shots_on_goal', 'away_shots_on_goal', 'home_shots_off_goal', 'away_shots_off_goal',\n",
    "        'home_total_shots', 'away_total_shots', 'home_blocked_shots', 'away_blocked_shots',\n",
    "        'home_shots_insidebox', 'away_shots_insidebox', 'home_shots_outsidebox', 'away_shots_outsidebox',\n",
    "        'home_ball_possession', 'away_ball_possession', 'home_yellow_cards', 'away_yellow_cards',\n",
    "        'home_red_cards', 'away_red_cards', 'home_goalkeeper_saves', 'away_goalkeeper_saves',\n",
    "        'home_total_passes', 'away_total_passes', 'home_passes_accurate', 'away_passes_accurate',\n",
    "        'home_passes_percentage', 'away_passes_percentage'\n",
    "    ]\n",
    "\n",
    "    X = df[features].fillna(0)\n",
    "    y = df['result']\n",
    "    return X, y, features\n",
    "\n",
    "# Step 3: Train Models\n",
    "def train_models(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        \"LightGBM\": LGBMClassifier(),\n",
    "        \"CatBoost\": CatBoostClassifier(verbose=0)\n",
    "    }\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Training {model_name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    return models, X.columns.tolist()\n",
    "\n",
    "# Step 4: Predict Upcoming Fixtures and Save to Database\n",
    "def predict_upcoming_fixtures(models, features):\n",
    "    today = datetime.now()\n",
    "    next_week = today + timedelta(days=7)\n",
    "\n",
    "    conn = sqlite3.connect(DATABASE_PATH)\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        f.fixture_id,\n",
    "        f.date,\n",
    "        f.home_team AS home_team_name,\n",
    "        f.away_team AS away_team_name,\n",
    "        s1.league_position AS home_league_position,\n",
    "        s2.league_position AS away_league_position,\n",
    "        s1.points AS home_points,\n",
    "        s2.points AS away_points,\n",
    "        rf_home.rolling_points AS home_rolling_points,\n",
    "        rf_home.rolling_wins AS home_rolling_wins,\n",
    "        rf_home.rolling_draws AS home_rolling_draws,\n",
    "        rf_home.rolling_losses AS home_rolling_losses,\n",
    "        rf_away.rolling_points AS away_rolling_points,\n",
    "        rf_away.rolling_wins AS away_rolling_wins,\n",
    "        rf_away.rolling_draws AS away_rolling_draws,\n",
    "        rf_away.rolling_losses AS away_rolling_losses\n",
    "    FROM fixtures f\n",
    "    LEFT JOIN standings s1\n",
    "        ON f.home_team_id = s1.team_id AND f.league_season = s1.season\n",
    "    LEFT JOIN standings s2\n",
    "        ON f.away_team_id = s2.team_id AND f.league_season = s2.season\n",
    "    LEFT JOIN recent_form rf_home ON f.home_team_id = rf_home.team_id\n",
    "    LEFT JOIN recent_form rf_away ON f.away_team_id = rf_away.team_id\n",
    "    WHERE f.status = 'Not Started'\n",
    "      AND f.date BETWEEN '{today.strftime('%Y-%m-%d')}' AND '{next_week.strftime('%Y-%m-%d')}';\n",
    "    \"\"\"\n",
    "    upcoming_fixtures = pd.read_sql_query(query, conn)\n",
    "\n",
    "    for feature in features:\n",
    "        if feature not in upcoming_fixtures.columns:\n",
    "            upcoming_fixtures[feature] = 0  # Fill missing stats with 0\n",
    "\n",
    "    X_upcoming = upcoming_fixtures[features].fillna(0)\n",
    "\n",
    "    best_model = models[\"XGBoost\"]\n",
    "    predictions = best_model.predict(X_upcoming)\n",
    "    predicted_probabilities = best_model.predict_proba(X_upcoming)\n",
    "\n",
    "    prediction_labels = {0: 'Home Win', 1: 'Draw', 2: 'Away Win'}\n",
    "    upcoming_fixtures['predicted_result'] = pd.Series(predictions).map(prediction_labels)\n",
    "    upcoming_fixtures['home_probability'] = (predicted_probabilities[:, 0] * 100).round(2)\n",
    "    upcoming_fixtures['draw_probability'] = (predicted_probabilities[:, 1] * 100).round(2)\n",
    "    upcoming_fixtures['away_probability'] = (predicted_probabilities[:, 2] * 100).round(2)\n",
    "\n",
    "    # Save predictions to the database\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        CREATE\n",
    "        TABLE IF NOT EXISTS predictions (\n",
    "            fixture_id INTEGER PRIMARY KEY,\n",
    "            date TEXT,\n",
    "            home_team_name TEXT,\n",
    "            away_team_name TEXT,\n",
    "            predicted_result TEXT,\n",
    "            home_probability REAL,\n",
    "            draw_probability REAL,\n",
    "            away_probability REAL,\n",
    "            last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "\n",
    "    # Insert or replace predictions\n",
    "    for _, row in upcoming_fixtures.iterrows():\n",
    "        cursor.execute('''\n",
    "            INSERT OR REPLACE INTO predictions (\n",
    "                fixture_id, date, home_team_name, away_team_name, predicted_result, \n",
    "                home_probability, draw_probability, away_probability, last_updated\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)\n",
    "        ''', (\n",
    "            row['fixture_id'], row['date'], row['home_team_name'], row['away_team_name'],\n",
    "            row['predicted_result'], row['home_probability'], row['draw_probability'], row['away_probability']\n",
    "        ))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"Predictions saved to the database.\")\n",
    "\n",
    "# Main Execution Flow\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Fetching training data...\")\n",
    "    training_data = get_training_data()\n",
    "    print(f\"Training data fetched: {len(training_data)} rows.\")\n",
    "\n",
    "    print(\"Preparing features...\")\n",
    "    X, y, features = prepare_features(training_data)\n",
    "\n",
    "    print(\"Training models...\")\n",
    "    models, feature_order = train_models(X, y)\n",
    "\n",
    "    print(\"Predicting upcoming fixtures...\")\n",
    "    predict_upcoming_fixtures(models, feature_order)\n",
    "\n",
    "    print(\"Process complete!\")\n"
   ],
   "id": "f9863371f95226a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching training data...\n",
      "Training data fetched: 27408 rows.\n",
      "Preparing features...\n",
      "Training models...\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howar\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:01:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1764\n",
      "[LightGBM] [Info] Number of data points in the train set: 21926, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score -0.837962\n",
      "[LightGBM] [Info] Start training from score -1.348260\n",
      "[LightGBM] [Info] Start training from score -1.178575\n",
      "Training CatBoost...\n",
      "Predicting upcoming fixtures...\n",
      "Predictions saved to the database.\n",
      "Process complete!\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:01:28.375149Z",
     "start_time": "2024-11-20T19:01:28.361150Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ba51be75f4e88f81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:01:28.468466Z",
     "start_time": "2024-11-20T19:01:28.455412Z"
    }
   },
   "cell_type": "code",
   "source": "#Predict Odds",
   "id": "7485619d1b023f89",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:01:28.484308Z",
     "start_time": "2024-11-20T19:01:28.474411Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c99aa0879ed63ada",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:01:28.532166Z",
     "start_time": "2024-11-20T19:01:28.518163Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c60bb1c4e4101911",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:01:43.068285Z",
     "start_time": "2024-11-20T19:01:28.565805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "BASE_DIRECTORY = r\"C:\\Users\\howar\\football_research_advanced\\2.0\\England\\Football_Predictions\\data\"\n",
    "DATABASE_PATH = os.path.join(BASE_DIRECTORY, \"football_data.db\")\n",
    "BASE_URL = \"https://v3.football.api-sports.io\"\n",
    "API_KEY = os.getenv(\"x-rapidapi-key\")\n",
    "\n",
    "\n",
    "def fetch_odds(fixture_id, bet=1):\n",
    "    headers = {\n",
    "        \"x-rapidapi-host\": \"v3.football.api-sports.io\",\n",
    "        \"x-rapidapi-key\": API_KEY,\n",
    "    }\n",
    "    params = {\n",
    "        \"fixture\": fixture_id,\n",
    "        \"bet\": bet\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/odds\", headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching odds: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_odds_to_db(fixture_id, odds_data):\n",
    "    conn = sqlite3.connect(DATABASE_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create the odds table if it doesn't exist\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS odds (\n",
    "            fixture_id INTEGER PRIMARY KEY,\n",
    "            best_home_odd REAL,\n",
    "            best_draw_odd REAL,\n",
    "            best_away_odd REAL,\n",
    "            best_home_bookmaker TEXT,\n",
    "            best_draw_bookmaker TEXT,\n",
    "            best_away_bookmaker TEXT,\n",
    "            last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    bookmakers = odds_data.get('response', [])[0].get('bookmakers', [])\n",
    "    best_odds = {\n",
    "        \"Home\": {\"odd\": 0, \"bookmaker\": None},\n",
    "        \"Draw\": {\"odd\": 0, \"bookmaker\": None},\n",
    "        \"Away\": {\"odd\": 0, \"bookmaker\": None},\n",
    "    }\n",
    "\n",
    "    for bookmaker in bookmakers:\n",
    "        bookmaker_name = bookmaker['name']\n",
    "        bets = bookmaker.get('bets', [])\n",
    "        for bet in bets:\n",
    "            if bet['id'] == 1:  # Match Winner bet type\n",
    "                for value in bet['values']:\n",
    "                    outcome = value['value']\n",
    "                    odd = float(value['odd'])\n",
    "                    if odd > best_odds[outcome][\"odd\"]:\n",
    "                        best_odds[outcome] = {\"odd\": odd, \"bookmaker\": bookmaker_name}\n",
    "\n",
    "    best_home_odd = best_odds[\"Home\"][\"odd\"]\n",
    "    best_home_bookmaker = best_odds[\"Home\"][\"bookmaker\"]\n",
    "    best_draw_odd = best_odds[\"Draw\"][\"odd\"]\n",
    "    best_draw_bookmaker = best_odds[\"Draw\"][\"bookmaker\"]\n",
    "    best_away_odd = best_odds[\"Away\"][\"odd\"]\n",
    "    best_away_bookmaker = best_odds[\"Away\"][\"bookmaker\"]\n",
    "\n",
    "    cursor.execute('''\n",
    "        INSERT OR REPLACE INTO odds (\n",
    "            fixture_id, best_home_odd, best_draw_odd, best_away_odd, \n",
    "            best_home_bookmaker, best_draw_bookmaker, best_away_bookmaker, last_updated\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)\n",
    "    ''', (fixture_id, best_home_odd, best_draw_odd, best_away_odd,\n",
    "          best_home_bookmaker, best_draw_bookmaker, best_away_bookmaker))\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"Odds for fixture ID {fixture_id} saved successfully.\")\n",
    "\n",
    "\n",
    "def get_fixtures_for_next_7_days():\n",
    "    conn = sqlite3.connect(DATABASE_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    today = datetime.date.today()\n",
    "    next_week = today + datetime.timedelta(days=7)\n",
    "\n",
    "    query = f'''\n",
    "    SELECT fixture_id\n",
    "    FROM fixtures\n",
    "    WHERE date BETWEEN '{today}' AND '{next_week}';\n",
    "    '''\n",
    "    fixture_ids = cursor.execute(query).fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    return [fixture_id[0] for fixture_id in fixture_ids]\n",
    "\n",
    "\n",
    "def fetch_and_save_odds_for_fixtures():\n",
    "    fixture_ids = get_fixtures_for_next_7_days()\n",
    "    print(f\"Found {len(fixture_ids)} fixtures in the next 7 days.\")\n",
    "\n",
    "    for fixture_id in fixture_ids:\n",
    "        odds_response = fetch_odds(fixture_id, bet=1)\n",
    "\n",
    "        if odds_response and odds_response.get(\"results\", 0) > 0:\n",
    "            save_odds_to_db(fixture_id, odds_response)\n",
    "        else:\n",
    "            print(f\"No odds data available for fixture ID: {fixture_id}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_and_save_odds_for_fixtures()\n"
   ],
   "id": "716d2cb99d4004ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 fixtures in the next 7 days.\n",
      "Odds for fixture ID 1208133 saved successfully.\n",
      "Odds for fixture ID 1208134 saved successfully.\n",
      "Odds for fixture ID 1208135 saved successfully.\n",
      "Odds for fixture ID 1208136 saved successfully.\n",
      "Odds for fixture ID 1208137 saved successfully.\n",
      "Odds for fixture ID 1208138 saved successfully.\n",
      "Odds for fixture ID 1208139 saved successfully.\n",
      "Odds for fixture ID 1208140 saved successfully.\n",
      "Odds for fixture ID 1208141 saved successfully.\n",
      "Odds for fixture ID 1208142 saved successfully.\n",
      "Odds for fixture ID 1216023 saved successfully.\n",
      "Odds for fixture ID 1216024 saved successfully.\n",
      "Odds for fixture ID 1216025 saved successfully.\n",
      "Odds for fixture ID 1216026 saved successfully.\n",
      "Odds for fixture ID 1216027 saved successfully.\n",
      "Odds for fixture ID 1216028 saved successfully.\n",
      "Odds for fixture ID 1216029 saved successfully.\n",
      "Odds for fixture ID 1216030 saved successfully.\n",
      "Odds for fixture ID 1216031 saved successfully.\n",
      "Odds for fixture ID 1216032 saved successfully.\n",
      "Odds for fixture ID 1216033 saved successfully.\n",
      "Odds for fixture ID 1216034 saved successfully.\n",
      "No odds data available for fixture ID: 1216035\n",
      "No odds data available for fixture ID: 1216036\n",
      "No odds data available for fixture ID: 1216038\n",
      "No odds data available for fixture ID: 1216039\n",
      "No odds data available for fixture ID: 1216040\n",
      "No odds data available for fixture ID: 1216041\n",
      "No odds data available for fixture ID: 1216042\n",
      "No odds data available for fixture ID: 1216445\n",
      "No odds data available for fixture ID: 1216447\n",
      "No odds data available for fixture ID: 1216454\n",
      "No odds data available for fixture ID: 1216515\n",
      "No odds data available for fixture ID: 1216517\n",
      "No odds data available for fixture ID: 1216518\n",
      "No odds data available for fixture ID: 1216521\n",
      "No odds data available for fixture ID: 1216525\n",
      "No odds data available for fixture ID: 1216526\n",
      "Odds for fixture ID 1216587 saved successfully.\n",
      "Odds for fixture ID 1216588 saved successfully.\n",
      "Odds for fixture ID 1216589 saved successfully.\n",
      "Odds for fixture ID 1216590 saved successfully.\n",
      "Odds for fixture ID 1216591 saved successfully.\n",
      "Odds for fixture ID 1216592 saved successfully.\n",
      "Odds for fixture ID 1216593 saved successfully.\n",
      "Odds for fixture ID 1216594 saved successfully.\n",
      "Odds for fixture ID 1216595 saved successfully.\n",
      "Odds for fixture ID 1216596 saved successfully.\n",
      "Odds for fixture ID 1216597 saved successfully.\n",
      "Odds for fixture ID 1216598 saved successfully.\n",
      "No odds data available for fixture ID: 1217006\n",
      "No odds data available for fixture ID: 1217078\n",
      "Odds for fixture ID 1217139 saved successfully.\n",
      "Odds for fixture ID 1217140 saved successfully.\n",
      "Odds for fixture ID 1217141 saved successfully.\n",
      "Odds for fixture ID 1217142 saved successfully.\n",
      "Odds for fixture ID 1217143 saved successfully.\n",
      "Odds for fixture ID 1217144 saved successfully.\n",
      "Odds for fixture ID 1217145 saved successfully.\n",
      "Odds for fixture ID 1217146 saved successfully.\n",
      "Odds for fixture ID 1217147 saved successfully.\n",
      "Odds for fixture ID 1217148 saved successfully.\n",
      "Odds for fixture ID 1217149 saved successfully.\n",
      "Odds for fixture ID 1217150 saved successfully.\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:01:43.116264Z",
     "start_time": "2024-11-20T19:01:43.103282Z"
    }
   },
   "cell_type": "code",
   "source": "# New script for saving to DB",
   "id": "3e3e9e7687963b39",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:03:28.172297Z",
     "start_time": "2024-11-20T19:03:28.114255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "BASE_DIRECTORY = r\"C:\\Users\\howar\\football_research_advanced\\2.0\\England\\Football_Predictions\\data\"\n",
    "DATABASE_PATH = os.path.join(BASE_DIRECTORY, \"football_data.db\")\n",
    "\n",
    "def ensure_predictions_table_columns():\n",
    "    \"\"\"\n",
    "    Ensure the `predictions` table has all the necessary columns.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DATABASE_PATH)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Add the required columns if they do not exist\n",
    "    try:\n",
    "        cursor.execute(\"ALTER TABLE predictions ADD COLUMN best_home_odd REAL;\")\n",
    "    except sqlite3.OperationalError:\n",
    "        pass  # Column already exists\n",
    "\n",
    "    try:\n",
    "        cursor.execute(\"ALTER TABLE predictions ADD COLUMN best_draw_odd REAL;\")\n",
    "    except sqlite3.OperationalError:\n",
    "        pass  # Column already exists\n",
    "\n",
    "    try:\n",
    "        cursor.execute(\"ALTER TABLE predictions ADD COLUMN best_away_odd REAL;\")\n",
    "    except sqlite3.OperationalError:\n",
    "        pass  # Column already exists\n",
    "\n",
    "    try:\n",
    "        cursor.execute(\"ALTER TABLE predictions ADD COLUMN best_home_bookmaker TEXT;\")\n",
    "    except sqlite3.OperationalError:\n",
    "        pass  # Column already exists\n",
    "\n",
    "    try:\n",
    "        cursor.execute(\"ALTER TABLE predictions ADD COLUMN best_draw_bookmaker TEXT;\")\n",
    "    except sqlite3.OperationalError:\n",
    "        pass  # Column already exists\n",
    "\n",
    "    try:\n",
    "        cursor.execute(\"ALTER TABLE predictions ADD COLUMN best_away_bookmaker TEXT;\")\n",
    "    except sqlite3.OperationalError:\n",
    "        pass  # Column already exists\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def get_predictions_with_odds():\n",
    "    \"\"\"\n",
    "    Fetch predictions and odds, merge them, and save back to the database.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DATABASE_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Fetch predictions joined with odds\n",
    "    predictions_query = '''\n",
    "    SELECT \n",
    "        p.fixture_id,\n",
    "        p.date,\n",
    "        p.home_team_name,\n",
    "        p.away_team_name,\n",
    "        p.predicted_result,\n",
    "        p.home_probability,\n",
    "        p.draw_probability,\n",
    "        p.away_probability,\n",
    "        o.best_home_odd,\n",
    "        o.best_draw_odd,\n",
    "        o.best_away_odd,\n",
    "        o.best_home_bookmaker,\n",
    "        o.best_draw_bookmaker,\n",
    "        o.best_away_bookmaker\n",
    "    FROM predictions p\n",
    "    LEFT JOIN odds o\n",
    "        ON p.fixture_id = o.fixture_id\n",
    "    '''\n",
    "    predictions = pd.read_sql_query(predictions_query, conn)\n",
    "\n",
    "    # Update predictions table with odds\n",
    "    for _, row in predictions.iterrows():\n",
    "        cursor.execute('''\n",
    "            INSERT OR REPLACE INTO predictions (\n",
    "                fixture_id, date, home_team_name, away_team_name, predicted_result,\n",
    "                home_probability, draw_probability, away_probability,\n",
    "                best_home_odd, best_draw_odd, best_away_odd,\n",
    "                best_home_bookmaker, best_draw_bookmaker, best_away_bookmaker,\n",
    "                last_updated\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)\n",
    "        ''', (\n",
    "            row['fixture_id'], row['date'], row['home_team_name'], row['away_team_name'],\n",
    "            row['predicted_result'], row['home_probability'], row['draw_probability'],\n",
    "            row['away_probability'], row['best_home_odd'], row['best_draw_odd'],\n",
    "            row['best_away_odd'], row['best_home_bookmaker'], row['best_draw_bookmaker'],\n",
    "            row['best_away_bookmaker']\n",
    "        ))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"Predictions updated with odds and saved to the database.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Ensuring predictions table has required columns...\")\n",
    "    ensure_predictions_table_columns()\n",
    "\n",
    "    print(\"Integrating odds into predictions...\")\n",
    "    get_predictions_with_odds()\n",
    "\n",
    "    print(\"Integration complete!\")\n"
   ],
   "id": "69579ad616b28405",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensuring predictions table has required columns...\n",
      "Integrating odds into predictions...\n",
      "Predictions updated with odds and saved to the database.\n",
      "Integration complete!\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:03:31.692991Z",
     "start_time": "2024-11-20T19:03:31.654993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "BASE_DIRECTORY = r\"C:\\Users\\howar\\football_research_advanced\\2.0\\England\\Football_Predictions\\data\"\n",
    "DATABASE_PATH = os.path.join(BASE_DIRECTORY, \"football_data.db\")\n",
    "\n",
    "# Step 1: Load Predictions and Odds\n",
    "def load_predictions_with_odds():\n",
    "    conn = sqlite3.connect(DATABASE_PATH)\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        p.fixture_id, \n",
    "        p.date, \n",
    "        p.home_team_name, \n",
    "        p.away_team_name, \n",
    "        p.predicted_result, \n",
    "        p.home_probability, \n",
    "        p.draw_probability, \n",
    "        p.away_probability,\n",
    "        o.best_home_odd, \n",
    "        o.best_draw_odd, \n",
    "        o.best_away_odd\n",
    "    FROM predictions p\n",
    "    LEFT JOIN odds o ON p.fixture_id = o.fixture_id\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "# Step 2: Calculate Implied Probabilities and Value Bets\n",
    "def calculate_value_bets(predictions_df):\n",
    "    # Implied probabilities from odds\n",
    "    predictions_df['implied_home_prob'] = 1 / predictions_df['best_home_odd']\n",
    "    predictions_df['implied_draw_prob'] = 1 / predictions_df['best_draw_odd']\n",
    "    predictions_df['implied_away_prob'] = 1 / predictions_df['best_away_odd']\n",
    "    \n",
    "    # Flag value bets\n",
    "    predictions_df['value_home'] = predictions_df['home_probability'] / 100 > predictions_df['implied_home_prob']\n",
    "    predictions_df['value_draw'] = predictions_df['draw_probability'] / 100 > predictions_df['implied_draw_prob']\n",
    "    predictions_df['value_away'] = predictions_df['away_probability'] / 100 > predictions_df['implied_away_prob']\n",
    "    \n",
    "    return predictions_df\n",
    "\n",
    "# Step 3: Safely Update Predictions Table\n",
    "def update_predictions_table(predictions_df):\n",
    "    conn = sqlite3.connect(DATABASE_PATH)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Add columns to the predictions table if they don't exist\n",
    "    try:\n",
    "        cursor.execute('ALTER TABLE predictions ADD COLUMN value_home BOOLEAN DEFAULT 0;')\n",
    "    except sqlite3.OperationalError:\n",
    "        pass  # Column already exists\n",
    "    \n",
    "    try:\n",
    "        cursor.execute('ALTER TABLE predictions ADD COLUMN value_draw BOOLEAN DEFAULT 0;')\n",
    "    except sqlite3.OperationalError:\n",
    "        pass  # Column already exists\n",
    "    \n",
    "    try:\n",
    "        cursor.execute('ALTER TABLE predictions ADD COLUMN value_away BOOLEAN DEFAULT 0;')\n",
    "    except sqlite3.OperationalError:\n",
    "        pass  # Column already exists\n",
    "    \n",
    "    # Update each row with the value bets\n",
    "    for _, row in predictions_df.iterrows():\n",
    "        cursor.execute('''\n",
    "            UPDATE predictions\n",
    "            SET value_home = ?,\n",
    "                value_draw = ?,\n",
    "                value_away = ?\n",
    "            WHERE fixture_id = ?\n",
    "        ''', (row['value_home'], row['value_draw'], row['value_away'], row['fixture_id']))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"Value bets updated in the predictions table.\")\n",
    "\n",
    "# Main Script\n",
    "if __name__ == \"__main__\":\n",
    "    # Load predictions and odds\n",
    "    predictions_df = load_predictions_with_odds()\n",
    "    \n",
    "    # Calculate value bets\n",
    "    predictions_df = calculate_value_bets(predictions_df)\n",
    "    \n",
    "    # Update the predictions table\n",
    "    update_predictions_table(predictions_df)\n",
    "    print(\"Process complete: Value bets added to the predictions table.\")\n",
    "\n"
   ],
   "id": "2d3db5e73cb5626a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value bets updated in the predictions table.\n",
      "Process complete: Value bets added to the predictions table.\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:01:43.418194600Z",
     "start_time": "2024-11-20T18:57:50.428741Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1145b36b5e451dea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9f8ca36e955deb1e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
